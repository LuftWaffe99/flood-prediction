{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './shapefiles/zipped_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extractROI\n\u001b[1;32m     12\u001b[0m ee\u001b[38;5;241m.\u001b[39mAuthenticate()\n\u001b[1;32m     13\u001b[0m ee\u001b[38;5;241m.\u001b[39mInitialize(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvirtual-rarity-426212-p6\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/issai-srp/sources/utils.py:86\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Upload zipfiles from the bucket in GCS to GEE\u001b[39;00m\n\u001b[1;32m     84\u001b[0m bucket_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzipped-shapefiles\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zip_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./shapefiles/zipped_files\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m zip_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     88\u001b[0m         gcs_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './shapefiles/zipped_files'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import geemap\n",
    "import ee\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from utils import extractROI\n",
    "\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=\"virtual-rarity-426212-p6\")\n",
    "Map = geemap.Map()\n",
    "\n",
    "\n",
    "LAI_BAND = 'Lai_500m'\n",
    "FOREST_BAND = 'Percent_Tree_Cover'\n",
    "GREEN_BAND = 'NDVI'\n",
    "ZIPPED_FHAPEFILES_DIR = \"./zipped_files\"\n",
    "START_DATE = ee.Date('2000-02-18')\n",
    "END_DATE = ee.Date('2023-01-01')\n",
    "ASSET_FODLER = \"projects/virtual-rarity-426212-p6/assets/shapefiles\"\n",
    "\n",
    "# Each zipfile is FeatureCollection type asset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Vegetation():\n",
    "    \n",
    "    def __init__(self, start_date: str, end_date: str, land_cover: str = 'MODIS/061/MOD15A2H'):\n",
    "        \n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date \n",
    "        self.landcover_dataset = ee.ImageCollection(land_cover).\\\n",
    "                    filterDate(start_date, end_date).select(LAI_BAND)\n",
    "                    \n",
    "        self.forest_fraction = ee.ImageCollection(\"MODIS/006/MOD44B\").\\\n",
    "                    filterDate('2000-03-05', '2020-03-05').select(FOREST_BAND)\n",
    "                    \n",
    "        self.green_fraction = ee.ImageCollection(\"MODIS/061/MOD13Q1\").\\\n",
    "                    filterDate(start_date, end_date).select(GREEN_BAND)\n",
    "        \n",
    "        self.roi_lst, self.basin_names = extractROI(ASSET_FODLER)\n",
    "        self.months  = ee.List.sequence(1, 12)\n",
    "     \n",
    "        \n",
    "    \n",
    "    def _compute_monthly_lai_stats(self, month: str)->ee.ImageCollection:\n",
    "        \n",
    "        monthlyLai = self.landcover_dataset.filter(ee.Filter.calendarRange(month, month, 'month'))\n",
    "        \n",
    "        monthly_mean_lai = monthlyLai.mean().rename('lai_mean')\n",
    "        monthly_max_lai = monthlyLai.max().rename('lai_max') # max of a month across the years \n",
    "        monthly_min_lai = monthlyLai.min().rename('lai_min') # min of a month across the years \n",
    "        \n",
    "        monthly_stats_lai = monthly_mean_lai.addBands([monthly_max_lai, monthly_min_lai])\n",
    "        \n",
    "        return monthly_stats_lai.set('month', month)\n",
    "        \n",
    "        \n",
    "    def _computeOneLaiStats(self, roi: ee.Geometry)->Tuple[float, float]:\n",
    "        \n",
    "        monthly_lai_stats = self.landcover_dataset.\\\n",
    "                            fromImages(self.months.map(lambda month: self._compute_monthly_lai_stats(month)))\n",
    "        \n",
    "        \n",
    "        clipped_lai_images =  monthly_lai_stats.map(lambda img: img.clip(roi))\n",
    "        lai_mean_images = clipped_lai_images.select('lai_mean')\n",
    "        \n",
    "    \n",
    "        max_lai_mean = lai_mean_images.reduce(ee.Reducer.max()).reduceRegion(\n",
    "                            reducer=ee.Reducer.mean(),\n",
    "                            geometry=roi,\n",
    "                            scale=500,  \n",
    "                            maxPixels=1e9\n",
    "                            )\n",
    "        \n",
    "        min_lai_mean = lai_mean_images.reduce(ee.Reducer.min()).reduceRegion(\n",
    "                            reducer=ee.Reducer.mean(),\n",
    "                            geometry=roi,\n",
    "                            scale=500,  \n",
    "                            maxPixels=1e9\n",
    "                            )\n",
    "        \n",
    "        num_max_lai_mean = max_lai_mean.getInfo()['lai_mean_max']\n",
    "        num_min_lai_mean = min_lai_mean.getInfo()['lai_mean_min']\n",
    "        mean_diff = num_max_lai_mean - num_min_lai_mean\n",
    "        \n",
    "        return round(num_max_lai_mean/4, 7), round(mean_diff/4,7)  # 31/8-day composite\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _computeForestFractionStats(self, roi: ee.Geometry)->float:\n",
    "        \n",
    "        clipped_tree_cover = self.forest_fraction.map(lambda img: img.clip(roi))\n",
    "        \n",
    "        mean_tree_cover = clipped_tree_cover.reduce(ee.Reducer.mean()).reduceRegion(\n",
    "                            reducer = ee.Reducer.mean(),\n",
    "                            geometry=roi,\n",
    "                            scale=250,\n",
    "                            maxPixels=1e9\n",
    "                          )\n",
    "        \n",
    "        return round(mean_tree_cover.getInfo()['Percent_Tree_Cover_mean']/100, 7)\n",
    "    \n",
    "    # aggregate green fractions for a month across the years \n",
    "    def _computeOneGreenFraction(self, month: ee.Number)->ee.Image:\n",
    "        \n",
    "        monthly_ndvi = self.green_fraction.filter(ee.Filter.calendarRange(month, month, 'month'))\n",
    "        mean_monthly_ndvi = monthly_ndvi.mean().rename('mean_ndvi')\n",
    "        return mean_monthly_ndvi.set('month', month)\n",
    "    \n",
    "    \n",
    "    # TODO: Check everything!\n",
    "    def _computeGreenFractionStats(self, roi: ee.Geometry) -> Tuple[float, float, float]:\n",
    "        mean_monthly_ndvi = self.green_fraction.\\\n",
    "                            fromImages(self.months.map(lambda month: self._computeOneGreenFraction(month)))\n",
    "        \n",
    "        clipped_imgs = mean_monthly_ndvi.map(lambda img: img.clip(roi)).select('mean_ndvi') \n",
    "        \n",
    "        # Reduce the ImageCollection to a single Image by calculating the mean\n",
    "        mean_image = clipped_imgs.mean()\n",
    "        \n",
    "        # Combine reducers to calculate mean, min, and max\n",
    "        combined_reducer = ee.Reducer.mean().combine(\n",
    "            reducer2=ee.Reducer.minMax(),\n",
    "            sharedInputs=True\n",
    "        )\n",
    "        \n",
    "        # Apply the combined reducer\n",
    "        stats = mean_image.reduceRegion(\n",
    "            reducer=combined_reducer,\n",
    "            geometry=roi,\n",
    "            scale=250,\n",
    "            maxPixels=1e9\n",
    "        ).getInfo()\n",
    "        \n",
    "        # Extract values and apply scaling factor\n",
    "        scaling_factor = 0.0001\n",
    "        mean_ndvi = stats['mean_ndvi_mean'] * scaling_factor\n",
    "        min_ndvi = stats['mean_ndvi_min'] * scaling_factor\n",
    "        max_ndvi = stats['mean_ndvi_max'] * scaling_factor\n",
    "        \n",
    "        gvf_max = (mean_ndvi - min_ndvi) / (max_ndvi - min_ndvi)\n",
    "        gvf_diff = max_ndvi - min_ndvi\n",
    "        \n",
    "        return round(gvf_max, 7), round(gvf_diff, 7), round(mean_ndvi, 7)\n",
    "\n",
    "\n",
    "        \n",
    "    def computeAllStats(self):\n",
    "        \n",
    "        table = {\"lai_max\": [], \"lai_diff\": [], \"forest_frac\": [],\n",
    "                 \"gvf_max\": [], \"gvf_diff\": []}\n",
    "        \n",
    "        for idx, roi in tqdm(enumerate(self.roi_lst)):\n",
    "            \n",
    "            if idx==5:\n",
    "                break\n",
    "            lai_max, lai_diff = self._computeOneLaiStats(roi)\n",
    "            forest_frac = self._computeForestFractionStats(roi)\n",
    "            gvf_max, gvf_diff, _ = self._computeGreenFractionStats(roi)\n",
    "            \n",
    "            table['lai_max'].append(lai_max)\n",
    "            table['lai_diff'].append(lai_diff)\n",
    "            table['forest_frac'].append(forest_frac)\n",
    "            table['gvf_max'].append(gvf_max)\n",
    "            table['gvf_diff'].append(gvf_diff)\n",
    "            \n",
    "        dataframe = pd.DataFrame(table, index=self.basin_names[:5])\n",
    "        return dataframe\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "vegi = Vegetation(START_DATE, END_DATE)\n",
    "result1, result2, result3 = vegi._computeGreenFractionStats(vegi.roi_lst[5])\n",
    "print(result1, result2 ,result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
