{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 5/106 [00:08<02:45,  1.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_gages2</th>\n",
       "      <th>elev_mean</th>\n",
       "      <th>slope_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>58489.499676</td>\n",
       "      <td>1473.256087</td>\n",
       "      <td>12.473454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11063</th>\n",
       "      <td>97.984369</td>\n",
       "      <td>1176.012101</td>\n",
       "      <td>11.648020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11068</th>\n",
       "      <td>2953.293899</td>\n",
       "      <td>1429.457014</td>\n",
       "      <td>10.788666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11077</th>\n",
       "      <td>2521.671927</td>\n",
       "      <td>1449.100238</td>\n",
       "      <td>7.657305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>222.672868</td>\n",
       "      <td>593.480450</td>\n",
       "      <td>2.310260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        area_gages2    elev_mean  slope_mean\n",
       "11001  58489.499676  1473.256087   12.473454\n",
       "11063     97.984369  1176.012101   11.648020\n",
       "11068   2953.293899  1429.457014   10.788666\n",
       "11077   2521.671927  1449.100238    7.657305\n",
       "11090    222.672868   593.480450    2.310260"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import geemap\n",
    "import ee\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from utils import extractROI\n",
    "\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=\"virtual-rarity-426212-p6\")\n",
    "Map = geemap.Map()\n",
    "\n",
    "\n",
    "LAI_BAND = \"Lai_500m\"\n",
    "FOREST_BAND = \"Percent_Tree_Cover\"\n",
    "GREEN_BAND = \"NDVI\"\n",
    "ZIPPED_FHAPEFILES_DIR = \"../zipped_files\"\n",
    "START_DATE = ee.Date(\"2000-02-18\")\n",
    "END_DATE = ee.Date(\"2023-01-01\")\n",
    "ASSET_FODLER = \"projects/virtual-rarity-426212-p6/assets/shapefiles\"\n",
    "\n",
    "# Each zipfile is FeatureCollection type asset\n",
    "\n",
    "\n",
    "class BasinMetrics:\n",
    "\n",
    "    def __init__(self, asset_fldr: str):\n",
    "        self.roi_lst, self.basin_names = extractROI(asset_fldr)\n",
    "        self.terrain = ee.Image(\"USGS/SRTMGL1_003\")  # contains one image\n",
    "\n",
    "    def computeBasinArea(self, roi: ee.Geometry) -> float:\n",
    "        area_km2 = round(roi.area().getInfo() / 1e6, 7)\n",
    "        return area_km2\n",
    "\n",
    "    def _computeOneElevationSlope(self, roi: ee.Geometry) -> Tuple[Dict, Dict]:\n",
    "\n",
    "        elev_stats = self.terrain.reduceRegion(\n",
    "            reducer=ee.Reducer.mean().combine(\n",
    "                reducer2=ee.Reducer.minMax(), sharedInputs=True\n",
    "            ),\n",
    "            geometry=roi,\n",
    "            scale=30,\n",
    "            maxPixels=1e9,\n",
    "        ).getInfo()\n",
    "\n",
    "        slope = ee.Terrain.slope(self.terrain)\n",
    "\n",
    "        slope_stats = slope.reduceRegion(\n",
    "            reducer=ee.Reducer.mean().combine(\n",
    "                reducer2=ee.Reducer.minMax(), sharedInputs=True\n",
    "            ),\n",
    "            geometry=roi,\n",
    "            scale=30,\n",
    "            maxPixels=1e9,\n",
    "        ).getInfo()\n",
    "\n",
    "        return slope_stats, elev_stats\n",
    "\n",
    "    def computeAllElevationSlopeStats(self):\n",
    "\n",
    "        table = {\"area_gages2\": [], \"elev_mean\": [], \"slope_mean\": []}\n",
    "        bar_format = (\n",
    "            \"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "        )\n",
    "\n",
    "        for idx, roi in enumerate(tqdm(self.roi_lst, bar_format=bar_format)):\n",
    "\n",
    "            if idx == 5:\n",
    "                break\n",
    "\n",
    "            area_gages2 = self.computeBasinArea(roi)\n",
    "            slope_stats, elev_stats = self._computeOneElevationSlope(roi)\n",
    "\n",
    "            table[\"area_gages2\"].append(area_gages2)\n",
    "            table[\"slope_mean\"].append(slope_stats[\"slope_mean\"])\n",
    "            table[\"elev_mean\"].append(elev_stats[\"elevation_mean\"])\n",
    "\n",
    "        dataframe = pd.DataFrame(table, index=self.basin_names[:5])\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "class Vegetation:\n",
    "\n",
    "    def __init__(\n",
    "        self, start_date: str, end_date: str, land_cover: str = \"MODIS/061/MOD15A2H\"\n",
    "    ):\n",
    "\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.landcover_dataset = (\n",
    "            ee.ImageCollection(land_cover)\n",
    "            .filterDate(start_date, end_date)\n",
    "            .select(LAI_BAND)\n",
    "        )\n",
    "\n",
    "        self.forest_fraction = (\n",
    "            ee.ImageCollection(\"MODIS/006/MOD44B\")\n",
    "            .filterDate(\"2000-03-05\", \"2020-03-05\")\n",
    "            .select(FOREST_BAND)\n",
    "        )\n",
    "\n",
    "        self.green_fraction = (\n",
    "            ee.ImageCollection(\"MODIS/061/MOD13Q1\")\n",
    "            .filterDate(start_date, end_date)\n",
    "            .select(GREEN_BAND)\n",
    "        )\n",
    "\n",
    "        self.roi_lst, self.basin_names = extractROI(ASSET_FODLER)\n",
    "        self.months = ee.List.sequence(1, 12)\n",
    "\n",
    "    def _compute_monthly_lai_stats(self, month: str) -> ee.ImageCollection:\n",
    "\n",
    "        monthlyLai = self.landcover_dataset.filter(\n",
    "            ee.Filter.calendarRange(month, month, \"month\")\n",
    "        )\n",
    "\n",
    "        monthly_mean_lai = monthlyLai.mean().rename(\"lai_mean\")\n",
    "        monthly_max_lai = monthlyLai.max().rename(\n",
    "            \"lai_max\"\n",
    "        )  # max of a month across the years\n",
    "        monthly_min_lai = monthlyLai.min().rename(\n",
    "            \"lai_min\"\n",
    "        )  # min of a month across the years\n",
    "\n",
    "        monthly_stats_lai = monthly_mean_lai.addBands(\n",
    "            [monthly_max_lai, monthly_min_lai]\n",
    "        )\n",
    "\n",
    "        return monthly_stats_lai.set(\"month\", month)\n",
    "\n",
    "    def _computeOneLaiStats(self, roi: ee.Geometry) -> Tuple[float, float]:\n",
    "\n",
    "        monthly_lai_stats = self.landcover_dataset.fromImages(\n",
    "            self.months.map(lambda month: self._compute_monthly_lai_stats(month))\n",
    "        )\n",
    "\n",
    "        clipped_lai_images = monthly_lai_stats.map(lambda img: img.clip(roi))\n",
    "        lai_mean_images = clipped_lai_images.select(\"lai_mean\")\n",
    "\n",
    "        max_lai_mean = lai_mean_images.reduce(ee.Reducer.max()).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=roi, scale=500, maxPixels=1e9\n",
    "        )\n",
    "\n",
    "        min_lai_mean = lai_mean_images.reduce(ee.Reducer.min()).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=roi, scale=500, maxPixels=1e9\n",
    "        )\n",
    "\n",
    "        num_max_lai_mean = max_lai_mean.getInfo()[\"lai_mean_max\"]\n",
    "        num_min_lai_mean = min_lai_mean.getInfo()[\"lai_mean_min\"]\n",
    "        mean_diff = num_max_lai_mean - num_min_lai_mean\n",
    "\n",
    "        return round(num_max_lai_mean / 4, 7), round(\n",
    "            mean_diff / 4, 7\n",
    "        )  # 31/8-day composite\n",
    "\n",
    "    def _computeForestFractionStats(self, roi: ee.Geometry) -> float:\n",
    "\n",
    "        clipped_tree_cover = self.forest_fraction.map(lambda img: img.clip(roi))\n",
    "\n",
    "        mean_tree_cover = clipped_tree_cover.reduce(ee.Reducer.mean()).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=roi, scale=250, maxPixels=1e9\n",
    "        )\n",
    "\n",
    "        return round(mean_tree_cover.getInfo()[\"Percent_Tree_Cover_mean\"] / 100, 7)\n",
    "\n",
    "    # aggregate green fractions for a month across the years\n",
    "    def _computeOneGreenFraction(self, month: ee.Number) -> ee.Image:\n",
    "\n",
    "        monthly_ndvi = self.green_fraction.filter(\n",
    "            ee.Filter.calendarRange(month, month, \"month\")\n",
    "        )\n",
    "        mean_monthly_ndvi = monthly_ndvi.mean().rename(\"mean_ndvi\")\n",
    "        return mean_monthly_ndvi.set(\"month\", month)\n",
    "\n",
    "    # TODO: Check everything!\n",
    "    def _computeGreenFractionStats(\n",
    "        self, roi: ee.Geometry\n",
    "    ) -> Tuple[float, float, float]:\n",
    "        mean_monthly_ndvi = self.green_fraction.fromImages(\n",
    "            self.months.map(lambda month: self._computeOneGreenFraction(month))\n",
    "        )\n",
    "\n",
    "        clipped_imgs = mean_monthly_ndvi.map(lambda img: img.clip(roi)).select(\n",
    "            \"mean_ndvi\"\n",
    "        )\n",
    "\n",
    "        # Reduce the ImageCollection to a single Image by calculating the mean\n",
    "        mean_image = clipped_imgs.mean()\n",
    "\n",
    "        # Combine reducers to calculate mean, min, and max\n",
    "        combined_reducer = ee.Reducer.mean().combine(\n",
    "            reducer2=ee.Reducer.minMax(), sharedInputs=True\n",
    "        )\n",
    "\n",
    "        # Apply the combined reducer\n",
    "        stats = mean_image.reduceRegion(\n",
    "            reducer=combined_reducer, geometry=roi, scale=250, maxPixels=1e9\n",
    "        ).getInfo()\n",
    "\n",
    "        # Extract values and apply scaling factor\n",
    "        scaling_factor = 0.0001\n",
    "        mean_ndvi = stats[\"mean_ndvi_mean\"] * scaling_factor\n",
    "        min_ndvi = stats[\"mean_ndvi_min\"] * scaling_factor\n",
    "        max_ndvi = stats[\"mean_ndvi_max\"] * scaling_factor\n",
    "\n",
    "        gvf_max = (mean_ndvi - min_ndvi) / (max_ndvi - min_ndvi)\n",
    "        gvf_diff = max_ndvi - min_ndvi\n",
    "\n",
    "        return round(gvf_max, 7), round(gvf_diff, 7), round(mean_ndvi, 7)\n",
    "\n",
    "    def computeAllStats(self):\n",
    "\n",
    "        table = {\n",
    "            \"lai_max\": [],\n",
    "            \"lai_diff\": [],\n",
    "            \"forest_frac\": [],\n",
    "            \"gvf_max\": [],\n",
    "            \"gvf_diff\": [],\n",
    "        }\n",
    "\n",
    "        bar_format = (\n",
    "            \"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "        )\n",
    "\n",
    "        for idx, roi in enumerate(tqdm(self.roi_lst, bar_format=bar_format)):\n",
    "\n",
    "            if idx == 5:\n",
    "                break\n",
    "            lai_max, lai_diff = self._computeOneLaiStats(roi)\n",
    "            forest_frac = self._computeForestFractionStats(roi)\n",
    "            gvf_max, gvf_diff, _ = self._computeGreenFractionStats(roi)\n",
    "\n",
    "            table[\"lai_max\"].append(lai_max)\n",
    "            table[\"lai_diff\"].append(lai_diff)\n",
    "            table[\"forest_frac\"].append(forest_frac)\n",
    "            table[\"gvf_max\"].append(gvf_max)\n",
    "            table[\"gvf_diff\"].append(gvf_diff)\n",
    "\n",
    "        dataframe = pd.DataFrame(table, index=self.basin_names[:5])\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "# # vegi = Vegetation(START_DATE, END_DATE)\n",
    "# basinMetric = BasinMetrics(ASSET_FODLER)\n",
    "# result1 = basinMetric.computeAllElevationSlopeStats()\n",
    "# result1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
<<<<<<<< HEAD:computeStats.ipynb
   "source": []
========
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature - Mean: 4.176115436237432, Amplitude: -20.59695029374134, Phase Shift: 287\n",
      "Precipitation - Mean: 1.8335811055452118, Amplitude: 0.379849368203114, Phase Shift: 104\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def prcp_model(t, mean_P, d_P, s_P):\n",
    "    return mean_P * (1 + d_P * np.sin(2 * np.pi * (t - s_P) / 365))\n",
    "\n",
    "\n",
    "def temp_model(t, mean_T, delta_T, s_T):\n",
    "    return mean_T + delta_T * np.sin(2 * np.pi * (t - s_T) / 365)\n",
    "\n",
    "\n",
    "data_csv = pd.read_csv(\n",
    "    \"../KZ-ABA_Aksuat_meteo.txt\", sep=r\"\\s+\", engine=\"python\", parse_dates=[\"date\"]\n",
    ")\n",
    "data_csv[\"date\"] = pd.to_datetime(data_csv[\"date\"])\n",
    "data = data_csv.loc[:, [\"date\", \"prcp\", \"t_mean\"]]\n",
    "\n",
    "\n",
    "data.set_index(data[\"date\"], inplace=True)\n",
    "data.drop(columns=[\"date\"], axis=1, inplace=True)\n",
    "data[\"prcp\"].interpolate(method=\"time\", inplace=True)\n",
    "data[\"t_mean\"].interpolate(method=\"time\", inplace=True)\n",
    "\n",
    "data[\"mov_prcp\"] = data[\"prcp\"].rolling(window=30, min_periods=15).mean()\n",
    "data[\"mov_temp\"] = data[\"t_mean\"].rolling(window=10, min_periods=5).mean()\n",
    "\n",
    "truncated_data = data.truncate(\n",
    "    before=pd.Timestamp(\"2000-01-15\"), after=pd.Timestamp(\"2024-03-15\")\n",
    ")\n",
    "truncated_data[\"month_day\"] = truncated_data.index.strftime(\"%m-%d\")\n",
    "mean_data = truncated_data.groupby(\"month_day\").mean()\n",
    "# mean_data.drop(columns=['prcp', 't_mean'], inplace=True)\n",
    "mean_data.reset_index(inplace=True)\n",
    "\n",
    "t = mean_data.index.values\n",
    "T = mean_data[\"t_mean\"].values\n",
    "P = mean_data[\"prcp\"].values\n",
    "\n",
    "initial_guess_T = [np.mean(T), (np.max(T) - np.min(T)) / 2]\n",
    "initial_guess_P = [np.mean(P), (np.max(P) - np.min(P)) / (2 * np.mean(P))]\n",
    "best_fit_T = None\n",
    "best_fit_P = None\n",
    "min_residual_T = float(\"inf\")\n",
    "min_residual_P = float(\"inf\")\n",
    "\n",
    "for s_T in range(0, 365):\n",
    "    try:\n",
    "        # popt, pcov = curve_fit(func, xdata, ydata)\n",
    "        params_T, _ = curve_fit(\n",
    "            lambda t, T_mean, delta_T: temp_model(t, T_mean, delta_T, s_T),\n",
    "            t,\n",
    "            T,\n",
    "            p0=initial_guess_T,\n",
    "        )\n",
    "        residual_T = np.sum((T - temp_model(t, *params_T, s_T)) ** 2)\n",
    "        if residual_T < min_residual_T:\n",
    "            min_residual_T = residual_T\n",
    "            best_fit_T = (params_T[0], params_T[1], s_T)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "for s_P in range(0, 365):\n",
    "    try:\n",
    "        params_P, _ = curve_fit(\n",
    "            lambda t, P_mean, d_P: prcp_model(t, P_mean, d_P, s_P),\n",
    "            t,\n",
    "            P,\n",
    "            p0=initial_guess_P,\n",
    "        )\n",
    "        residual_P = np.sum((P - prcp_model(t, *params_P, s_P)) ** 2)\n",
    "        if residual_P < min_residual_P:\n",
    "            min_residual_P = residual_P\n",
    "            best_fit_P = (params_P[0], params_P[1], s_P)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "\n",
    "T_mean, Delta_T, s_T = best_fit_T\n",
    "P_mean, d_P, s_P = best_fit_P\n",
    "\n",
    "print(f\"Temperature - Mean: {T_mean}, Amplitude: {Delta_T}, Phase Shift: {s_T}\")\n",
    "print(f\"Precipitation - Mean: {P_mean}, Amplitude: {d_P}, Phase Shift: {s_P}\")"
   ]
>>>>>>>> flood/main:gee_python/compute_stats.ipynb
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
